{"cells":[{"cell_type":"markdown","source":["\n","# Hands-On Exercise: Word Embedding using One-Hot Encoding"],"metadata":{"id":"QwcUbyPRt7Fy"},"id":"QwcUbyPRt7Fy"},{"cell_type":"code","execution_count":1,"id":"556ddc33","metadata":{"id":"556ddc33","executionInfo":{"status":"ok","timestamp":1727260521335,"user_tz":-330,"elapsed":1758,"user":{"displayName":"Amit Oberoi","userId":"12159142296586998026"}}},"outputs":[],"source":["\n","\n","# Step 1: Define the corpus\n","corpus = [\n","    'I love natural language processing',\n","    'Natural language processing is amazing',\n","    'I love learning new techniques',\n","    'Techniques in natural language processing are evolving',\n","    'NIC Experts are learning Natural Language Processing'\n","]\n","\n"]},{"cell_type":"code","source":["# Step 2: Create a Vocabulary\n","# Convert to lowercase and split each sentence into words\n","vocab = set([word.lower() for sentence in corpus for word in sentence.split()])\n","\n","# Assign an index to each word\n","word_to_index = {word: index for index, word in enumerate(vocab)}\n","print(\"Vocabulary:\", word_to_index)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kCv0QIKsuQTD","executionInfo":{"status":"ok","timestamp":1727260539793,"user_tz":-330,"elapsed":510,"user":{"displayName":"Amit Oberoi","userId":"12159142296586998026"}},"outputId":"aae7625b-af90-42fa-e642-315495d03d2a"},"id":"kCv0QIKsuQTD","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Vocabulary: {'techniques': 0, 'evolving': 1, 'i': 2, 'natural': 3, 'amazing': 4, 'processing': 5, 'love': 6, 'learning': 7, 'is': 8, 'new': 9, 'in': 10, 'are': 11, 'experts': 12, 'language': 13, 'nic': 14}\n"]}]},{"cell_type":"code","source":["# Step 3: Implement One-Hot Encoding\n","import numpy as np\n","\n","# Function to create a one-hot vector for a given word\n","def one_hot_encode(word, word_to_index, vocab_size):\n","    one_hot_vector = np.zeros(vocab_size)\n","    one_hot_vector[word_to_index[word]] = 1\n","    return one_hot_vector\n","\n"],"metadata":{"id":"Ko7660pMuViq","executionInfo":{"status":"ok","timestamp":1727260568688,"user_tz":-330,"elapsed":462,"user":{"displayName":"Amit Oberoi","userId":"12159142296586998026"}}},"id":"Ko7660pMuViq","execution_count":3,"outputs":[]},{"cell_type":"code","source":["# One-hot encode the first sentence\n","sentence = 'I love natural language processing'.lower().split()\n","vocab_size = len(vocab)\n","\n","for word in sentence:\n","    one_hot_vector = one_hot_encode(word, word_to_index, vocab_size)\n","    print(f\"Word: {word}, One-Hot: {one_hot_vector}\")\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dj9vyMZMubQi","executionInfo":{"status":"ok","timestamp":1727260600884,"user_tz":-330,"elapsed":5,"user":{"displayName":"Amit Oberoi","userId":"12159142296586998026"}},"outputId":"b3c50607-0485-46dc-c8aa-fa082d28c61f"},"id":"Dj9vyMZMubQi","execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Word: i, One-Hot: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","Word: love, One-Hot: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n","Word: natural, One-Hot: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n","Word: language, One-Hot: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n","Word: processing, One-Hot: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"]}]},{"cell_type":"code","source":["# Step 4: Encode Entire Corpus\n","def encode_sentence(sentence, word_to_index, vocab_size):\n","    encoded_sentence = []\n","    for word in sentence.lower().split():\n","        encoded_sentence.append(one_hot_encode(word, word_to_index, vocab_size))\n","    return np.array(encoded_sentence)\n","\n"],"metadata":{"id":"4slfPyXqudHT","executionInfo":{"status":"ok","timestamp":1727260672711,"user_tz":-330,"elapsed":445,"user":{"displayName":"Amit Oberoi","userId":"12159142296586998026"}}},"id":"4slfPyXqudHT","execution_count":5,"outputs":[]},{"cell_type":"code","source":["print (vocab)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q19tOCHEwKp0","executionInfo":{"status":"ok","timestamp":1727260701964,"user_tz":-330,"elapsed":491,"user":{"displayName":"Amit Oberoi","userId":"12159142296586998026"}},"outputId":"b6a2fe58-67c9-4e6b-dbaf-ed9d132a65e2"},"id":"Q19tOCHEwKp0","execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["{'techniques', 'evolving', 'i', 'natural', 'amazing', 'processing', 'love', 'learning', 'is', 'new', 'in', 'are', 'experts', 'language', 'nic'}\n"]}]},{"cell_type":"code","source":["# One-hot encode each sentence in the corpus\n","for sentence in corpus:\n","    encoded_matrix = encode_sentence(sentence, word_to_index, vocab_size)\n","    print(f\"Sentence: {sentence}\")\n","    print(\"One-Hot Encoded Matrix:\")\n","    print(encoded_matrix)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqWiCzcTueza","executionInfo":{"status":"ok","timestamp":1727260708803,"user_tz":-330,"elapsed":725,"user":{"displayName":"Amit Oberoi","userId":"12159142296586998026"}},"outputId":"d83230df-67be-44d1-f6b9-9e6cec711226"},"id":"rqWiCzcTueza","execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence: I love natural language processing\n","One-Hot Encoded Matrix:\n","[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","Sentence: Natural language processing is amazing\n","One-Hot Encoded Matrix:\n","[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","Sentence: I love learning new techniques\n","One-Hot Encoded Matrix:\n","[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"," [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","Sentence: Techniques in natural language processing are evolving\n","One-Hot Encoded Matrix:\n","[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n","Sentence: NIC Experts are learning Natural Language Processing\n","One-Hot Encoded Matrix:\n","[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"," [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n"," [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"]}]},{"cell_type":"markdown","source":["## Limitations of One-Hot Encoding:\n","### 1. Dimensionality: Each word in a large corpus will have a very sparse vector, leading to inefficient storage and computation.\n","### 2. Semantic Information: One-hot encoding does not capture any information about the relationship between words. Words with similar meanings have orthogonal vectors, which does not reflect their semantic similarity.\n"],"metadata":{"id":"K5Ycr60KvcWj"},"id":"K5Ycr60KvcWj"}],"metadata":{"colab":{"provenance":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":5}